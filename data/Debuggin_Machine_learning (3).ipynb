{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2990f81-5ea8-4f00-9fd1-e59eb82b7259",
   "metadata": {},
   "source": [
    "## Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "id": "68490589-3b69-4891-ab58-092fa4d3a704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:47:59.521883Z",
     "start_time": "2024-06-18T01:47:56.888291Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "import ta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5b7d1095-786e-4f12-b37d-b4fb4dd4e485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:47:59.804356Z",
     "start_time": "2024-06-18T01:47:59.521883Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import optuna"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d1ca3f0d-63d2-4780-8352-6adeefd86163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:47:59.808501Z",
     "start_time": "2024-06-18T01:47:59.804356Z"
    }
   },
   "source": [
    "list_of_equity = [\n",
    "    \"aapl_5m_train.csv\",\n",
    "    \"aapl_project_1m_test.csv\",\n",
    "    \"aapl_project_1m_train.csv\",\n",
    "    \"aapl_project_test.csv\",\n",
    "    \"aapl_project_train.csv\",\n",
    "    \"btc_project_1m_test.csv\",\n",
    "    \"btc_project_1m_train.csv\",\n",
    "    \"btc_project_test.csv\",\n",
    "    \"btc_project_train.csv\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c8114d5a-efe6-4e74-9822-cd0d38b6df64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:47:59.826496Z",
     "start_time": "2024-06-18T01:47:59.811763Z"
    }
   },
   "source": [
    "def reading_files(list_of_files : str):\n",
    "    \"\"\"\n",
    "    list of files is goint to be a list where all the files need \n",
    "    to be written as a string\n",
    "    \"\"\"\n",
    "\n",
    "    dict_files = dict()\n",
    "    for file in list_of_files:\n",
    "        dict_files[file] = pd.read_csv(file)\n",
    "    return dict_files"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "1474b7cf-ba5d-4cb4-bbd3-e393992705e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:00.560783Z",
     "start_time": "2024-06-18T01:47:59.826496Z"
    }
   },
   "source": [
    "files = reading_files(list_of_equity)\n",
    "data = files[\"aapl_project_train.csv\"]\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Timestamp  Gmtoffset             Datetime        Open        High  \\\n",
       "0  1654090200          0  2022-06-01 13:30:00  149.899993  150.600006   \n",
       "1  1654090500          0  2022-06-01 13:35:00  150.529998  151.080001   \n",
       "2  1654090800          0  2022-06-01 13:40:00  150.500000  150.889999   \n",
       "3  1654091100          0  2022-06-01 13:45:00  150.740005  151.520004   \n",
       "4  1654091400          0  2022-06-01 13:50:00  150.869995  151.509994   \n",
       "\n",
       "          Low       Close     Volume  \n",
       "0  149.880004  150.539993  4474349.0  \n",
       "1  150.289993  150.500000  2181281.0  \n",
       "2  150.270004  150.729995  1622128.0  \n",
       "3  150.500000  150.860000  2034927.0  \n",
       "4  150.759994  151.389404  1379313.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gmtoffset</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654090200</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 13:30:00</td>\n",
       "      <td>149.899993</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>149.880004</td>\n",
       "      <td>150.539993</td>\n",
       "      <td>4474349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654090500</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 13:35:00</td>\n",
       "      <td>150.529998</td>\n",
       "      <td>151.080001</td>\n",
       "      <td>150.289993</td>\n",
       "      <td>150.500000</td>\n",
       "      <td>2181281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654090800</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 13:40:00</td>\n",
       "      <td>150.500000</td>\n",
       "      <td>150.889999</td>\n",
       "      <td>150.270004</td>\n",
       "      <td>150.729995</td>\n",
       "      <td>1622128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1654091100</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 13:45:00</td>\n",
       "      <td>150.740005</td>\n",
       "      <td>151.520004</td>\n",
       "      <td>150.500000</td>\n",
       "      <td>150.860000</td>\n",
       "      <td>2034927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1654091400</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 13:50:00</td>\n",
       "      <td>150.869995</td>\n",
       "      <td>151.509994</td>\n",
       "      <td>150.759994</td>\n",
       "      <td>151.389404</td>\n",
       "      <td>1379313.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "400763e7-83d3-49ee-81d1-9864f24e90b9",
   "metadata": {},
   "source": [
    "## Indicadores"
   ]
  },
  {
   "cell_type": "code",
   "id": "dad77727-3d36-4e5d-8a67-68f8e029778f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:00.595529Z",
     "start_time": "2024-06-18T01:48:00.560783Z"
    }
   },
   "source": [
    "data_clean = data.loc[:, [\"Close\"]]\n",
    "data_clean[\"Y\"] = data_clean.shift(-15)\n",
    "data_clean[\"Close_t1\"] = data.loc[:, [\"Close\"]].shift(1)\n",
    "data_clean[\"Close_t2\"] = data.loc[:, [\"Close\"]].shift(2)\n",
    "data_clean[\"Close_t3\"] = data.loc[:, [\"Close\"]].shift(3)\n",
    "data_clean[\"Close_t4\"] = data.loc[:, [\"Close\"]].shift(4)\n",
    "data_clean[\"Close_t5\"] = data.loc[:, [\"Close\"]].shift(5)\n",
    "data_clean[\"rsi_10\"] = ((ta.momentum.RSIIndicator(data[\"Close\"], window=10)).rsi())\n",
    "data_clean[\"rsi_20\"] = ((ta.momentum.RSIIndicator(data[\"Close\"], window=20)).rsi())\n",
    "data_clean[\"rsi_30\"] = ((ta.momentum.RSIIndicator(data[\"Close\"], window=30)).rsi())\n",
    "data_clean[\"macd_10_24_7\"] = ((ta.trend.MACD(close=data[\"Close\"], window_slow=24, window_fast=10, window_sign=7)).macd())\n",
    "data_clean[\"macd_12_26_9\"] = ((ta.trend.MACD(close=data_clean[\"Close\"], window_slow=26, window_fast=12, window_sign=9)).macd())\n",
    "data_clean[\"macd_5_35_5\"] = ((ta.trend.MACD(close=data_clean[\"Close\"], window_slow=35, window_fast=5, window_sign=5)).macd())\n",
    "\n",
    "### bollinger bands\n",
    "bollinger_20_2 = ta.volatility.BollingerBands(close=data_clean[\"Close\"], window=20, window_dev=2)\n",
    "data_clean[\"bollinger_20_2_hband\"] = bollinger_20_2.bollinger_hband()\n",
    "data_clean[\"bollinger_20_2_lband\"] = bollinger_20_2.bollinger_lband()\n",
    "data_clean[\"bollinger_20_2_mavg\"] = bollinger_20_2.bollinger_mavg()\n",
    "\n",
    "bollinger_10_1_5 = ta.volatility.BollingerBands(close=data_clean[\"Close\"], window=10, window_dev=1.5)\n",
    "data_clean[\"bollinger_10_1_5_hband\"] = bollinger_10_1_5.bollinger_hband()\n",
    "data_clean[\"bollinger_10_1_5_lband\"] = bollinger_10_1_5.bollinger_lband()\n",
    "data_clean[\"bollinger_10_1_5_mavg\"] = bollinger_10_1_5.bollinger_mavg()\n",
    "\n",
    "bollinger_50_2_5 = ta.volatility.BollingerBands(close=data_clean[\"Close\"], window=50, window_dev=2.5)\n",
    "data_clean[\"bollinger_50_2_5_hband\"] = bollinger_50_2_5.bollinger_hband()\n",
    "data_clean[\"bollinger_50_2_5_lband\"] = bollinger_50_2_5.bollinger_lband()\n",
    "data_clean[\"bollinger_50_2_5_mavg\"] = bollinger_50_2_5.bollinger_mavg()\n",
    "data_clean = data_clean.dropna()\n",
    "\n",
    "# data_clean[\"atr_14\"] = (ta.volatility.AverageTrueRange(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)).average_true_range()\n",
    "# data_clean[\"atr_10\"] = (ta.volatility.AverageTrueRange(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=10)).average_true_range()\n",
    "# data_clean[\"atr_20\"] = (ta.volatility.AverageTrueRange(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=20)).average_true_range()\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5a84c88b-3266-4d14-b107-9ba54c3545e0",
   "metadata": {},
   "source": [
    "## Visualización en plotly"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b31d93e-4052-4101-8944-376856ee699d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:00.600224Z",
     "start_time": "2024-06-18T01:48:00.595529Z"
    }
   },
   "source": [
    "# import plotly.graph_objs as go\n",
    "# import plotly.io as pio\n",
    "\n",
    "# # Graficar Bandas de Bollinger\n",
    "# fig = go.Figure()\n",
    "\n",
    "# # Graficar el precio de cierre\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"Close\"], mode='lines', name='Close', line=dict(color='blue')))\n",
    "\n",
    "# # Graficar las Bandas de Bollinger para la configuración 20, 2\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_20_2_hband\"], mode='lines', name='Bollinger 20,2 High Band', line=dict(color='red')))\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_20_2_lband\"], mode='lines', name='Bollinger 20,2 Low Band', line=dict(color='green')))\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_20_2_mavg\"], mode='lines', name='Bollinger 20,2 MAVG', line=dict(color='orange')))\n",
    "\n",
    "# # Graficar las Bandas de Bollinger para la configuración 10, 1.5\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_10_1_5_hband\"], mode='lines', name='Bollinger 10,1.5 High Band', line=dict(color='purple')))\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_10_1_5_lband\"], mode='lines', name='Bollinger 10,1.5 Low Band', line=dict(color='brown')))\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_10_1_5_mavg\"], mode='lines', name='Bollinger 10,1.5 MAVG', line=dict(color='pink')))\n",
    "\n",
    "# # Graficar las Bandas de Bollinger para la configuración 50, 2.5\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_50_2_5_hband\"], mode='lines', name='Bollinger 50,2.5 High Band', line=dict(color='cyan')))\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_50_2_5_lband\"], mode='lines', name='Bollinger 50,2.5 Low Band', line=dict(color='magenta')))\n",
    "# fig.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"bollinger_50_2_5_mavg\"], mode='lines', name='Bollinger 50,2.5 MAVG', line=dict(color='yellow')))\n",
    "\n",
    "# fig.update_layout(title='Bandas de Bollinger', xaxis_title='Fecha', yaxis_title='Precio', legend_title='Indicadores')\n",
    "# pio.show(fig)\n",
    "\n",
    "# # Graficar ATR\n",
    "# fig_atr = go.Figure()\n",
    "\n",
    "# fig_atr.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"atr_14\"], mode='lines', name='ATR 14', line=dict(color='blue')))\n",
    "# fig_atr.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"atr_10\"], mode='lines', name='ATR 10', line=dict(color='red')))\n",
    "# fig_atr.add_trace(go.Scatter(x=data_clean.index, y=data_clean[\"atr_20\"], mode='lines', name='ATR 20', line=dict(color='green')))\n",
    "\n",
    "# fig_atr.update_layout(title='Average True Range (ATR)', xaxis_title='Fecha', yaxis_title='ATR', legend_title='Indicadores')\n",
    "# pio.show(fig_atr)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "08721e31-e5a3-45f5-b8c4-3c2127ef26b6",
   "metadata": {},
   "source": [
    "## Continue"
   ]
  },
  {
   "cell_type": "code",
   "id": "0b25cef8-44f8-4ab2-a376-1f9dca407971",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:00.622749Z",
     "start_time": "2024-06-18T01:48:00.600734Z"
    }
   },
   "source": [
    "data_clas = data_clean.drop(\"Y\", axis=1).copy()\n",
    "\n",
    "# Filtrar solo las columnas que contienen al menos un valor NaN\n",
    "columns_with_nan = data_clas.columns[data_clas.isna().any()].tolist()\n",
    "\n",
    "# Crear un nuevo DataFrame solo con las columnas filtradas\n",
    "df_with_nan = data_clas[columns_with_nan]\n",
    "df_with_nan"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, ...]\n",
       "\n",
       "[31112 rows x 0 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31315</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31316</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31318</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31319</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31112 rows × 0 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3f9d293f-3e39-414b-b1a0-51dd311dc34b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:00.627619Z",
     "start_time": "2024-06-18T01:48:00.622749Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def calculate_confusion_matrix_metrics(model, X_train, y_train):\n",
    "    y_pred = model.predict(X_train)\n",
    "\n",
    "    mat = confusion_matrix(y_train, y_pred)\n",
    "    true_negatives = mat[0, 0]\n",
    "    false_negatives = mat[1, 0]\n",
    "    true_positives = mat[1, 1]\n",
    "    false_positives = mat[0, 1]\n",
    "\n",
    "    return {\n",
    "        \"confusion_matrix\": mat,\n",
    "        \"true_negatives\": true_negatives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "        \"true_positives\": true_positives,\n",
    "        \"false_positives\": false_positives\n",
    "    }\n",
    "def fpr(false_positives, true_negatives):\n",
    "    return false_positives / (false_positives + true_negatives)\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7a1fae4b-26be-4f8a-9af6-9dfa2ef28b5a",
   "metadata": {},
   "source": [
    "## Dividimos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "fdb6933c-75d1-48b5-a54e-a82980dfe139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:00.641065Z",
     "start_time": "2024-06-18T01:48:00.627619Z"
    }
   },
   "source": [
    "data_clas[\"Y\"] = data_clas.Close < data_clas.Close.shift(-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_clas.drop(\"Y\", axis=1),\n",
    "                                                    data_clas.Y,\n",
    "                                                    shuffle=False, test_size=0.2)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "9eac53cb-5fa5-494b-b8c6-eaba1ff1afca",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:08.063416Z",
     "start_time": "2024-06-18T01:48:00.641065Z"
    }
   },
   "source": [
    "classification_model = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "logistic_pred = classification_model.predict(X_train)\n",
    "\n",
    "logistic_score = classification_model.score(X_train, y_train)\n",
    "\n",
    "\n",
    "### Classification V2\n",
    "\n",
    "\n",
    "\n",
    "ran_forest = RandomForestClassifier().fit(X_train,y_train)\n",
    "svc = SVC(C=500, max_iter=10_000).fit(X_train,y_train)\n",
    "xgb = XGBClassifier().fit(X_train,y_train)\n",
    "\n",
    "## F1 score\n",
    "\n",
    "### Regresión Lógistica\n",
    "f1_score_logistic = f1_score(y_train, classification_model.predict(X_train))\n",
    "f1_score_RanFore =  f1_score(y_train, ran_forest.predict(X_train))\n",
    "f1_score_svc = f1_score(y_train, svc.predict(X_train))\n",
    "f1_score_xgb =  f1_score(y_train, xgb.predict(X_train))\n",
    "\n",
    "\n",
    "\n",
    "metrics_svc = calculate_confusion_matrix_metrics(ran_forest, X_train, y_train)\n",
    "metrics_xgb = calculate_confusion_matrix_metrics(xgb, X_train, y_train)\n",
    "\n",
    "fpr_svc = fpr(metrics_svc[\"false_positives\"], metrics_svc[\"true_negatives\"])\n",
    "fpr_xgb = fpr(metrics_xgb[\"false_positives\"], metrics_xgb[\"true_negatives\"])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebmg\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 12\u001B[0m\n\u001B[0;32m      5\u001B[0m logistic_score \u001B[38;5;241m=\u001B[39m classification_model\u001B[38;5;241m.\u001B[39mscore(X_train, y_train)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m### Classification V2\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m ran_forest \u001B[38;5;241m=\u001B[39m \u001B[43mRandomForestClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m svc \u001B[38;5;241m=\u001B[39m SVC(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10_000\u001B[39m)\u001B[38;5;241m.\u001B[39mfit(X_train,y_train)\n\u001B[0;32m     14\u001B[0m xgb \u001B[38;5;241m=\u001B[39m XGBClassifier()\u001B[38;5;241m.\u001B[39mfit(X_train,y_train)\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    478\u001B[0m trees \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    479\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_estimator(append\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[0;32m    481\u001B[0m ]\n\u001B[0;32m    483\u001B[0m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[0;32m    486\u001B[0m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[0;32m    487\u001B[0m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[1;32m--> 489\u001B[0m trees \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mextend(trees)\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001B[0m, in \u001B[0;36m_parallel_build_trees\u001B[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001B[0m\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m class_weight \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced_subsample\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    190\u001B[0m         curr_sample_weight \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m compute_sample_weight(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced\u001B[39m\u001B[38;5;124m\"\u001B[39m, y, indices\u001B[38;5;241m=\u001B[39mindices)\n\u001B[1;32m--> 192\u001B[0m     \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurr_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    200\u001B[0m     tree\u001B[38;5;241m.\u001B[39m_fit(\n\u001B[0;32m    201\u001B[0m         X,\n\u001B[0;32m    202\u001B[0m         y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m         missing_values_in_feature_mask\u001B[38;5;241m=\u001B[39mmissing_values_in_feature_mask,\n\u001B[0;32m    206\u001B[0m     )\n",
      "File \u001B[1;32m~\\OneDrive\\Documentos\\GitHub\\official_second_proyect\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    462\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[0;32m    463\u001B[0m         splitter,\n\u001B[0;32m    464\u001B[0m         min_samples_split,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    469\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[0;32m    470\u001B[0m     )\n\u001B[1;32m--> 472\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    475\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "944eb2cf-b430-4e5e-a4e6-0b62339b9cce",
   "metadata": {},
   "source": [
    "## Optimizando SVG"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d1de01a-fbe2-4714-b93d-46f3c310d571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:08.068428Z",
     "start_time": "2024-06-18T01:48:08.068428Z"
    }
   },
   "source": [
    "# Definir la función objetivo\n",
    "def objective(trial):\n",
    "#     # Definir el rango de valores para los hiperparámetros\n",
    "    C = trial.suggest_float('C', 1e-2, 1000, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "    gamma = trial.suggest_float('gamma', 1e-2, 1e1, log=True)\n",
    "    \n",
    "    # Crear el modelo SVC\n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, max_iter=10_000)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "     # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    # Calculate FPR\n",
    "    fpr = fp / (fp + tn)\n",
    "    \n",
    "    return fpr\n",
    "\n",
    "# Crear un objeto de estudio\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# Ejecutar el proceso de optimización\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "\n",
    "# Mostrar los mejores parámetros\n",
    "#saved_study = optuna.load_study(study_name=study, storage=storage_url)\n",
    "#storage_url = \"sqlite:///example.db\"\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value:\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a8f3c50f-658e-4080-b20c-9fbb182cd910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:08.068428Z",
     "start_time": "2024-06-18T01:48:08.068428Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f8e28ef-1744-4997-b1ae-94f4ad1fd626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:48:08.068428Z",
     "start_time": "2024-06-18T01:48:08.068428Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1965279f-d23a-4fbe-b73e-86d9feea94cb",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca7250a7-a80b-4398-addc-197eaa13f6e4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbe6e9a7-06b1-4d3b-abee-f5c00b8e4b74",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
